{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPQokKfGrpu_"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ibB1lPorpvB"
   },
   "source": [
    "# Lab 8.2: Boosting\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "- Read the guides and hints then create the necessary analysis and code to find an answer and conclusion for the scenario below.\n",
    "- The baseline results (minimum) are:\n",
    "    - **Accuracy** = 0.9429\n",
    "    - **ROC AUC**  = 0.9333\n",
    "- Try to achieve better results!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Method   : Sequential\n",
    "ML Model : SGBoost and AdaBoost\n",
    "Focus on weak learners (Tends to overfit more than Bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LqafjJWZrpvG"
   },
   "source": [
    "## Scenario: Predicting Breast Cancer\n",
    "The dataset you are going to be using for this laboratory is popularly known as the **Wisconsin Breast Cancer** dataset. The task related to it is Classification.\n",
    "\n",
    "The dataset contains a total number of _10_ features labelled in either **benign** or **malignant** classes. The features have _699_ instances out of which _16_ feature values are missing. The dataset only contains numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vaxdobIZrpvI"
   },
   "source": [
    "# Step 1: Define the problem or question\n",
    "Identify the subject matter and the given or obvious questions that would be relevant in the field.\n",
    "\n",
    "## Potential Questions\n",
    "List the given or obvious questions.\n",
    "\n",
    "## Actual Question\n",
    "Choose the **one** question that should be answered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pip install xgboost\n",
    "'''\n",
    "# Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-O8FhgglrpvL"
   },
   "source": [
    "# Step 2: Find the Data\n",
    "## Wisconsin Breast Cancer DataSet\n",
    "- **Citation Request**\n",
    "\n",
    "    This breast cancer databases was obtained from the **University of Wisconsin Hospitals**, **Madison** from **Dr. William H. Wolberg**. If you publish results when using this database, then please include this information in your acknowledgements.\n",
    "\n",
    "- **Title**\n",
    "\n",
    "    Wisconsin Breast Cancer Database (January 8, 1991)\n",
    "\n",
    "- **Sources**\n",
    "    - **Creator**\n",
    "            Dr. WIlliam H. Wolberg (physician)\n",
    "            University of Wisconsin Hospitals\n",
    "            Madison, Wisconsin\n",
    "            USA\n",
    "    - **Donor**\n",
    "            Olvi Mangasarian (mangasarian@cs.wisc.edu)\n",
    "            Received by David W. Aha (aha@cs.jhu.edu)\n",
    "    - **Date**\n",
    "            15 July 1992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MT-Jy4rurpvN"
   },
   "source": [
    "# Step 3: Read the Data\n",
    "- Read the data\n",
    "- Perform some basic structural cleaning to facilitate the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ FILE\n",
    "file = '../Data/breast-cancer-wisconsin-data-old.csv'\n",
    "df = pd.read_csv(file)\n",
    "# SET COLUMN HEADER\n",
    "df.columns = ['ID','Clump_Thickness','Uniformity_Cell_Size','Uniformity_Cell_Shape','Marginal_Adhesion',\n",
    "              'Single_Epithelial_Cell_Size','Bare_Nuclei','Bland_Chromatin','Normal_Nucleoli','Mitoses','Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE NULL '?' VALUES\n",
    "df['Bare_Nuclei'] = df['Bare_Nuclei'].replace(['?'],'0')\n",
    "df.Bare_Nuclei = pd.to_numeric(df.Bare_Nuclei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET y to Appropriate Values \n",
    "df.replace( {'Class': {2:0, 4:1}}, inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ui6EbpzKrpvO"
   },
   "source": [
    "# Step 4: Explore and Clean the Data\n",
    "- Perform some initial simple **EDA** (Exploratory Data Analysis)\n",
    "- Check for\n",
    "    - **Number of features**\n",
    "    - **Data types**\n",
    "    - **Domains, Intervals**\n",
    "    - **Outliers** (are they valid or expurious data [read or measure errors])\n",
    "    - **Null** (values not present or coded [as zero of empty strings])\n",
    "    - **Missing Values** (coded [as zero of empty strings] or values not present)\n",
    "    - **Coded content** (classes identified by numbers or codes to represent absence of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djEFyiAvrpvP"
   },
   "source": [
    "# Step 5: Prepare the Data\n",
    "- Deal with the data as required by the modelling technique\n",
    "    - **Outliers** (remove or adjust if possible or necessary)\n",
    "    - **Null** (remove or interpolate if possible or necessary)\n",
    "    - **Missing Values** (remove or interpolate if possible or necessary)\n",
    "    - **Coded content** (transform if possible or necessary [str to number or vice-versa])\n",
    "    - **Normalisation** (if possible or necessary)\n",
    "    - **Feature Engeneer** (if useful or necessary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u_uEHN4zrpvQ"
   },
   "source": [
    "# Step 6: Modelling\n",
    "Refer to the Problem and Main Question.\n",
    "- What are the input variables (features)?\n",
    "- Is there an output variable (label)?\n",
    "- If there is an output variable:\n",
    "    - What is it?\n",
    "    - What is its type?\n",
    "- What type of Modelling is it?\n",
    "    - [ ] Supervised\n",
    "    - [ ] Unsupervised \n",
    "- What type of Modelling is it?\n",
    "    - [ ] Regression\n",
    "    - [ ] Classification (binary) \n",
    "    - [ ] Classification (multi-class)\n",
    "    - [ ] Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X and y\n",
    "X = df.drop(columns=['Class','ID'], axis=1)\n",
    "y = df['Class']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_-BoWumrpvR"
   },
   "source": [
    "# Step 7: Split the Data\n",
    "\n",
    "Need to check for **Supervised** modelling:\n",
    "- Number of known cases or observations\n",
    "- Define the split in Training/Test or Training/Validation/Test and their proportions\n",
    "- Check for unbalanced classes and how to keep or avoid it when spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i8IjhjqtrpvT"
   },
   "source": [
    "# Step 8: Define and Fit Models\n",
    "\n",
    "Define the model and its hyper-parameters.\n",
    "\n",
    "Consider the parameters and hyper-parameters of each model at each (re)run and after checking the efficiency of a model against the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nabc = AdaBoostClassifier(n_estimators=50, base_estimator=svc,learning_rate=1)\\n\\nbase_estimator : The weak learner used to train the model. (Default = DecisionTreeClassifier).\\nn_estimators   : Number of weak learners to train iteratively.\\nlearning_rate  : It contributes to the weights of weak learners. It uses 1 as a default value.\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "#from xgboost import XFBClassifier\n",
    "\n",
    "ADBclf = AdaBoostClassifier(n_estimators=50, learning_rate=1)   # Default = Decision Tree Classifier\n",
    "ADBclf.fit(X_train, y_train)\n",
    "\n",
    "'''\n",
    "abc = AdaBoostClassifier(n_estimators=50, base_estimator=svc,learning_rate=1)\n",
    "\n",
    "base_estimator : The weak learner used to train the model. (Default = DecisionTreeClassifier).\n",
    "n_estimators   : Number of weak learners to train iteratively.\n",
    "learning_rate  : It contributes to the weights of weak learners. It uses 1 as a default value.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9571428571428572"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADBclf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADBclf.predict([[0, 1, 2, 3, 4, 5, 6, 7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "svc=SVC(probability=True, kernel='linear')\n",
    "\n",
    "ADBClf_svc = AdaBoostClassifier(n_estimators=50, base_estimator=svc, learning_rate=1)\n",
    "ADBClf_svc.fit(X_train, y_train)\n",
    "ADBClf_svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eL5-13AgrpvU"
   },
   "source": [
    "# Step 9: Verify and Evaluate the Training Model\n",
    "- Use the **training** data to make predictions\n",
    "- Check for overfitting\n",
    "- What metrics are appropriate for the modelling approach used\n",
    "- For **Supervised** models:\n",
    "    - Check the **Training Results** with the **Training Predictions** during development\n",
    "- Analyse, modify the parameters and hyper-parameters and repeat (within reason) until the model does not improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nOf1r-RIrpvV"
   },
   "source": [
    "# Step 10: Make Predictions and Evaluate the Test Model\n",
    "**NOTE**: **Do this only after not making any more improvements in the model**.\n",
    "\n",
    "- Use the **test** data to make predictions\n",
    "- For **Supervised** models:\n",
    "    - Check the **Test Results** with the **Test Predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j8y6lKh2rpvW"
   },
   "source": [
    "# Step 11: Solve the Problem or Answer the Question\n",
    "The results of an analysis or modelling can be used:\n",
    "- As part of a product or process, so the model can make predictions when new input data is available\n",
    "- As part of a report including text and charts to help understand the problem\n",
    "- As input for further questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "© 2020 Institute of Data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Lab-8_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
